{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare liquid water effective droplet radii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import netCDF4 as nc\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import scipy.optimize\n",
    "import urllib.request\n",
    "import urllib.error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download TCWret data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_tcwret = \"TCWret.nc\"\n",
    "url = \"https://download.pangaea.de/dataset/933829/files/TCWret_PS106_PS107.nc\"\n",
    "if not os.path.exists(fname_tcwret):\n",
    "    try:\n",
    "        response = urllib.request.urlopen(url)\n",
    "    except urllib.error.HTTPError:\n",
    "        print(\"URL not found!\")\n",
    "    else:\n",
    "        data = response.read()\n",
    "        with open(fname_tcwret, 'wb') as fobj:\n",
    "            fobj.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define paths where to find the data. Data must be downloaded from Pangaea first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_cnet = '../get_cloudnet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from TCWret and save them as Pandas.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nc.Dataset(fname_tcwret) as f:\n",
    "    seconds = f.variables['time_of_measurement'][:]\n",
    "    r_ice = f.variables['ice_water_effective_droplet_radius'][:]\n",
    "    r_liq = f.variables['liquid_water_effective_droplet_radius'][:]\n",
    "    r_liq_err = f.variables['liquid_water_effective_droplet_radius_error'][:]\n",
    "    red_chi_2 = f.variables['reduced_chi_2'][:]\n",
    "    t_cw = f.variables['liquid_water_optical_depth'][:] + f.variables['ice_water_optical_depth'][:]\n",
    "    tl = f.variables['liquid_water_optical_depth'][:]\n",
    "    ti = f.variables['ice_water_optical_depth'][:]\n",
    "    pwv = f.variables['precipitable_water_vapour'][:]\n",
    "    \n",
    "time = np.array([])\n",
    "for ii in range(len(seconds)):\n",
    "    sec = int(seconds[ii])\n",
    "    time = np.concatenate((time, [dt.timedelta(seconds=sec) + dt.datetime(2017, 5, 1)]))\n",
    "    \n",
    "tcwret_raw = pd.DataFrame({'time': time, 'ti(1)': ti, 'tl(1)': tl, 'pwv(cm)': pwv, 'rice(um)': r_ice, 'rliq(um)': r_liq, 'drliq(um)': r_liq_err, 'red_chi_2(1)': red_chi_2, 'tcw(1)': t_cw})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply filtering of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_max = 6.0\n",
    "tau_min = 0.0\n",
    "\n",
    "idx_conv = np.where((tcwret_raw['red_chi_2(1)'] <= 1.0) & (tcwret_raw['red_chi_2(1)'] >= 0.0))[0]\n",
    "#idx_fi = np.where((tcwret_raw['fi(1)'] < 0.9))[0]\n",
    "#idx_valid = np.intersect(idx_conv, idx_fi)\n",
    "idx_tau = np.where((tcwret_raw['tcw(1)'] <= tau_max) & (tcwret_raw['tcw(1)'] >= tau_min))[0]\n",
    "idx_valid = np.intersect1d(idx_conv, idx_tau)\n",
    "idx_tau = np.where((tcwret_raw['ti(1)']/tcwret_raw['tcw(1)'] < 0.9))[0]\n",
    "idx_valid = np.intersect1d(idx_valid, idx_tau)\n",
    "tcwret = tcwret_raw.iloc[idx_valid]\n",
    "tcwret = tcwret.iloc[np.array(tcwret['rliq(um)']) <  np.array(tcwret['rice(um)'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Cloudnet data. Only allow retrieval flags 0,1,3 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rliq_martin_et_al(lwc):\n",
    "    k = 0.77\n",
    "    N_a = 50.0 # Aerosol number concentration in cm-3, see ERA5 documentation\n",
    "    N_d = -1.15 * 1e-3 * N_a**2 + 0.963 * N_a + 5.30\n",
    "    reff = ((3. * lwc)/(4. * np.pi * 1e3 * k * N_d))**(1./3.)\n",
    "    return reff*1e3\n",
    "\n",
    "reff_st_invalid = [2]\n",
    "cloudnet = {'time': [], 'rliq_Martin(um)': [], 'rliq(um)': [], 'drliq(um)': [], 'rliq_max(um)': [], 'drliq_max(um)': [], 'rliq_bottom(um)': [], 'drliq_bottom(um)': []}\n",
    "for file_ in sorted(os.listdir(path_cnet)):\n",
    "    if \".nc\" in file_:\n",
    "        with nc.Dataset(os.path.join(path_cnet, file_)) as f:\n",
    "            if \"cnet\" not in file_:\n",
    "                continue\n",
    "            day_month = dt.datetime.strptime(file_, 'cnet_%m_%d.nc')\n",
    "            day = dt.datetime(2017, day_month.month, day_month.day)\n",
    "            time = f.variables['datetime'][:]\n",
    "            lwp = f.variables['liquid_water_path_per_layer'][:]\n",
    "            lwc = f.variables['liquid_water_content'][:]\n",
    "            rliq = f.variables['reff_Frisch'][:]\n",
    "            rliq_err = f.variables['reff_Frisch_error'][:]\n",
    "            rliq_st = f.variables['reff_Frisch_status'][:]\n",
    "            #temp = f.variables['GDAS1_temperature'][:]\n",
    "            for time_idx in range(len(time)):\n",
    "                time_iter = day + dt.timedelta(seconds=int(np.round(time[time_idx]*3600)))\n",
    "                idx_liq = np.where(lwp[time_idx] > 0.0)[0]\n",
    "                reff_invalid = np.intersect1d(rliq_st[time_idx], np.array(reff_st_invalid))\n",
    "                if reff_invalid.size != 0: continue\n",
    "                if idx_liq.size == 0:\n",
    "                    continue \n",
    "                else:\n",
    "                    try:\n",
    "                        rliq_sum = np.mean(rliq[time_idx, idx_liq])##\n",
    "                        rliq_err_sum = np.mean(rliq_err[time_idx, idx_liq])#\n",
    "                        rliq_max_sum = np.max(rliq[time_idx, idx_liq])\n",
    "                        rliq_err_max_sum = np.max(rliq_err[time_idx, idx_liq])\n",
    "                        rliq_bottom_sum =  np.mean(rliq[time_idx, idx_liq[np.array([1,2])]])\n",
    "                        rliq_err_bottom_sum = np.mean(rliq_err[time_idx, idx_liq[np.array([1,2])]])\n",
    "                        ## Calculate reff using parameterization of Martin et al. (1994)\n",
    "                        rliq_martin = 0.0#calc_rliq_martin_et_al(np.max(lwc[time_idx, idx_liq]))\n",
    "                    except IndexError:\n",
    "                        continue\n",
    "                    except AttributeError:\n",
    "                        continue\n",
    "                cloudnet['time'].append(time_iter)\n",
    "                cloudnet['rliq(um)'].append(rliq_sum)\n",
    "                cloudnet['drliq(um)'].append(rliq_err_sum)\n",
    "                cloudnet['rliq_max(um)'].append(rliq_max_sum)\n",
    "                cloudnet['drliq_max(um)'].append(rliq_err_max_sum)\n",
    "                cloudnet['rliq_bottom(um)'].append(rliq_bottom_sum)\n",
    "                cloudnet['drliq_bottom(um)'].append(rliq_err_bottom_sum)\n",
    "                cloudnet['rliq_Martin(um)'].append(rliq_martin)\n",
    "cloudnet = pd.DataFrame(cloudnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove masked entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.array([])\n",
    "for ii in range(len(cloudnet)):\n",
    "    if not (np.ma.is_masked(cloudnet['rliq(um)'].iloc[ii]) or np.ma.is_masked(cloudnet['drliq(um)'].iloc[ii]) or \\\n",
    "    np.ma.is_masked(cloudnet['rliq_max(um)'].iloc[ii]) or np.ma.is_masked(cloudnet['drliq_max(um)'].iloc[ii]) or \\\n",
    "    np.ma.is_masked(cloudnet['rliq_bottom(um)'].iloc[ii]) or np.ma.is_masked(cloudnet['drliq_bottom(um)'].iloc[ii]) or np.ma.is_masked(cloudnet['rliq_Martin(um)'].iloc[ii])):\n",
    "        idx = np.concatenate((idx, [ii]))\n",
    "idx = np.array(idx, dtype=int)\n",
    "cloudnet = cloudnet.iloc[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define averaging time interval (minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Cloudnet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rliq_mean = []\n",
    "rliq_err = []\n",
    "rliq_max_mean = []\n",
    "rliq_err_max = []\n",
    "rliq_bottom_mean = []\n",
    "rliq_err_bottom = []\n",
    "rliq_martin_mean = []\n",
    "time_mean = []\n",
    "datetime_start = np.datetime64(\"2017-05-24T20:25:00\")\n",
    "datetime_iter = datetime_start\n",
    "datetime_stop = np.datetime64(\"2017-07-18T00:00:00\")\n",
    "while datetime_iter < datetime_stop:\n",
    "    idx = np.where((np.array(cloudnet['time']) > datetime_iter) & \\\n",
    "                   (np.array(cloudnet['time']) < datetime_iter+np.timedelta64(delta*60, 's')))[0]\n",
    "    if idx.size != 0:\n",
    "        rliq_mean.append(np.mean(np.array(cloudnet['rliq(um)'])[idx]))\n",
    "        rliq_err.append(np.mean(np.array(cloudnet['drliq(um)'])[idx]))\n",
    "        rliq_max_mean.append(np.mean(np.array(cloudnet['rliq_max(um)'])[idx]))\n",
    "        rliq_err_max.append(np.mean(np.array(cloudnet['drliq_max(um)'])[idx]))\n",
    "        rliq_bottom_mean.append(np.mean(np.array(cloudnet['rliq_bottom(um)'])[idx]))\n",
    "        rliq_err_bottom.append(np.mean(np.array(cloudnet['drliq_bottom(um)'])[idx]))\n",
    "        rliq_martin_mean.append(np.mean(np.array(cloudnet['rliq_Martin(um)'])[idx]))\n",
    "        time_mean.append(datetime_iter)\n",
    "    datetime_iter += np.timedelta64(delta*60, 's')\n",
    "    \n",
    "cloudnet_av = pd.DataFrame({'time': time_mean, 'rliq(um)': rliq_mean, 'drliq(um)': rliq_err, \\\n",
    "                            'rliq_max(um)': rliq_max_mean, 'drliq_max(um)': rliq_err_max, \\\n",
    "                            'rliq_bottom(um)': rliq_bottom_mean, 'drliq_bottom(um)': rliq_err_bottom, 'rliq_Martin(um)': rliq_martin_mean})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average TCWret data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rliq_mean = []\n",
    "drliq_mean = []\n",
    "time_mean = []\n",
    "red_chi2_mean = []\n",
    "tcw_mean = []\n",
    "pwv_mean = []\n",
    "datetime_start = np.datetime64(\"2017-05-24T20:25:00\")\n",
    "datetime_iter = datetime_start\n",
    "datetime_stop = np.datetime64(\"2017-07-18T00:00:00\")\n",
    "while datetime_iter < datetime_stop:\n",
    "    idx = np.where((np.array(tcwret['time']) > datetime_iter) & \\\n",
    "                   (np.array(tcwret['time']) < datetime_iter+np.timedelta64(delta*60, 's')))[0]\n",
    "    if idx.size != 0:\n",
    "        rliq_mean.append(np.mean(np.array(tcwret['rliq(um)'])[idx]))\n",
    "        drliq_mean.append(np.mean(np.array(tcwret['drliq(um)'])[idx]))\n",
    "        red_chi2_mean.append(np.mean(np.array(tcwret['red_chi_2(1)'])[idx]))\n",
    "        tcw_mean.append(np.mean(np.array(tcwret['tcw(1)'])[idx]))\n",
    "        pwv_mean.append(np.mean(np.array(tcwret['pwv(cm)'])[idx]))\n",
    "        time_mean.append(datetime_iter)\n",
    "    datetime_iter += np.timedelta64(delta*60, 's')\n",
    "    \n",
    "tcwret_av = pd.DataFrame({'time': time_mean, 'pwv(cm)': pwv_mean, 'tcw(1)': tcw_mean, 'drliq(um)': drliq_mean, 'rliq(um)': rliq_mean, 'red_chi_2': red_chi2_mean})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error scaling factor according to testcases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 3.35/2.13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate correlation coefficient, p-Value, mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect, idx_tcwret, idx_cloudnet = np.intersect1d(tcwret_av['time'], cloudnet_av['time'], return_indices=True)\n",
    "xax = np.array(tcwret_av['rliq(um)'].iloc[idx_tcwret])\n",
    "yax = np.array(cloudnet_av['rliq(um)'].iloc[idx_cloudnet])\n",
    "xax_err = np.array(tcwret_av['drliq(um)'].iloc[idx_tcwret])*scale\n",
    "yax_err = np.array(cloudnet_av['drliq(um)'].iloc[idx_cloudnet])\n",
    "diff = xax-yax\n",
    "pearsonr, pval = scipy.stats.pearsonr(xax, yax)\n",
    "\n",
    "print(\"Data\\t\\tcor\\tp-Value\\tMean\\tSD\\tNumber\")\n",
    "print(\"rliq All\\t\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{}\".format(pearsonr, pval, np.mean(diff), np.std(diff), xax.size))\n",
    "\n",
    "yax_max = np.array(cloudnet_av['rliq_max(um)'].iloc[idx_cloudnet]) \n",
    "yax_max_err = np.array(cloudnet_av['drliq_max(um)'].iloc[idx_cloudnet])\n",
    "diff_max = xax-yax_max\n",
    "pearsonr, pval = scipy.stats.pearsonr(xax, yax_max)\n",
    "\n",
    "print(\"rliq maximum\\t\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{}\".format(pearsonr, pval, np.mean(diff_max), np.std(diff_max), yax_max.size))\n",
    "\n",
    "yax_bottom = np.array(cloudnet_av['rliq_bottom(um)'].iloc[idx_cloudnet])\n",
    "yax_bottom_err =  np.array(cloudnet_av['drliq_bottom(um)'].iloc[idx_cloudnet])\n",
    "diff_bottom = xax-yax_bottom\n",
    "pearsonr, pval = scipy.stats.pearsonr(xax,yax_bottom)\n",
    "\n",
    "print(\"rliq bottom\\t\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{}\".format(pearsonr, pval, np.mean(diff_bottom), np.std(diff_bottom), diff_bottom.size))\n",
    "\n",
    "intersect, idx_tcwret, idx_cloudnet = np.intersect1d(tcwret_av['time'], cloudnet_av['time'], return_indices=True)\n",
    "cax = np.array(tcwret_av['pwv(cm)'].iloc[idx_tcwret])\n",
    "idx = np.where(cax < 1.0)[0]\n",
    "xax_pwv = xax[idx]\n",
    "yax_pwv = yax[idx]\n",
    "diff_pwv = xax_pwv - yax_pwv\n",
    "pearsonr, pval = scipy.stats.pearsonr(xax_pwv,yax_pwv)\n",
    "\n",
    "print(\"rliq PWV < 1cm\\t\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{:.2f}\\t{}\".format(pearsonr, pval, np.mean(diff_pwv), np.std(diff_pwv), diff_pwv.size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
